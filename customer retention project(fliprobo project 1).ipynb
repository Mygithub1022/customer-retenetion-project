{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly used to work on Business Problem\n",
    "\n",
    "Step by step approach to predicting and preventing customer retention\n",
    "Quick Examination of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pylab\n",
    "\n",
    "import time\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (ch.groupby('churn')['customerID'].count()/ch['customerID'].count()).plot.bar()\n",
    "df = plt.title('Proportion of customers')\n",
    "df = plt.ylabel('Proportion')\n",
    "df = plt.xlabel('Left (Yes) or Remained (No)')\n",
    "print('Overall Customer Churn percentage in the given dataset is {} %' .format(round(ch.churn.replace({'No' :0, 'Yes':}).mean()*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TotalCharges']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tenure']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCharges = df.TotalCharges.apply\n",
    "(lambdA X: 0 IF X == '' else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change No internet service to NoInt for brevity\n",
    "df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']] = df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].astype(str).replace({'No internet service': 'NoInt'})\n",
    "df['MultipleLines'] = df['MultipleLines'].replace({'No phone service':'NoPh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the customers into 4 groups of tenures and see their Churn Rate\n",
    "df = plt.figure(figsize=(12,4))\n",
    "df = plt.subplot(1,2,1)\n",
    "df['Tenure Group'] = 'Between 2 to 5 Years'\n",
    "ch.loc[ch['tenure'] >59,'Tenure Group'] = 'More than 5 Years' \n",
    "ch.loc[ch['tenure'] <= 24,'Tenure Group'] = '1 Year -> 2 Year'\n",
    "ch.loc[ch['tenure'] <= 12,'Tenure Group'] = 'Less Than 1 Year'\n",
    "df['Ch10'] = ch['Churn'].replace({'Yes':1,'No':0})\n",
    "df_rate = ch.groupby('Tenure Group')['Ch10'].mean().sort_values(ascending=False)\n",
    "(round(100*ch_rate,2)).plot.bar(color='pink')\n",
    "\n",
    "# Evaluate the Revenue Loss per month\n",
    "df['revloss'] = ch['MonthlyCharges']*ch['Ch10']\n",
    "ch = plt.ylabel('Churn Percentage')\n",
    "ch = plt.title('Percentage Churn Vs Tenures')\n",
    "ch = plt.subplot(1,2,2)\n",
    "revenue_group = ch.groupby('Tenure Group')['revloss'].sum().sort_values(ascending=False)\n",
    "(round(100*revenue_group/revenue_group.sum(),2)).plot.bar(color='g')\n",
    "df = plt.ylabel('Loss Percentage')\n",
    "df= plt.title('Percentage Revenue loss/Month Vs Tenure group')\n",
    "print('Total Revenue Lost/Month due to Churn: $',int(revenue_group.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stats for numeic types within Churn and No Churn group\n",
    "numvar = ['tenure','MonthlyCharges','TotalCharges']\n",
    "round(ch.groupby('Churn')[numvar].describe().T,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the tenure and see if it tells any story!\n",
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "df= plt.subplot(1,2,1)\n",
    "sns.distplot(ch.loc[ch.Churn=='No','tenure'],hist=True,color='g',kde=False)\n",
    "df = plt.title('Histogram of tenure values for loyal customers')\n",
    "df = plt.xlabel('Tenure in Months')\n",
    "df = plt.ylabel('People count')\n",
    "df = plt.subplot(1,2,2)\n",
    "ns.distplot(ch.loc[ch.Churn=='Yes','tenure'],hist=True,kde=False)\n",
    "df = plt.title('Histogram of tenure values for customers who left')\n",
    "df = plt.xlabel('Tenure in Months')\n",
    "df = plt.ylabel('People count')\n",
    "print(\"Mean Tenure of Two groups\\n\",round(ch.groupby('Churn').tenure.mean(),2))\n",
    "plt = plt.figure()\n",
    "df = ch[['Churn','tenure']].boxplot(by='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation between tenure*Monthly Vs TotalCharges\n",
    "print(\"Correlation between Monthly*tenure Vs. Total Charges:\",pearsonr(ch.tenure*ch.MonthlyCharges,ch.TotalCharges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch['Temp'] = ch.tenure*ch.MonthlyCharges\n",
    "lm = ols('TotalCharges ~ Temp',ch).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.drop(['Temp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.crosstab(ch.Contract,ch.Churn).plot.bar()\n",
    "df = plt.title('Churn Count for Contract')\n",
    "df = plt.ylabel('Churn/No Churn Counts')\n",
    "print('Mean Churn Across',ch.groupby('Contract')['Ch10'].mean())\n",
    "df = pd.crosstab(ch.PhoneService,ch.Churn).plot.bar(color='cb')\n",
    "plt = plt.title('Churn Count for Phone Service')\n",
    "plt = plt.ylabel('Churn/No Churn Counts')\n",
    "plt = pd.crosstab(ch.InternetService,ch.Churn).plot.bar(color='mr')\n",
    "plt = plt.title('Churn Count for Internet Service')\n",
    "plt = plt.ylabel('Churn/No Churn Counts')\n",
    "print('Mean Churn Across',ch.groupby('PhoneService')['Ch10'].mean())\n",
    "print('Mean Churn Across',ch.groupby('InternetService')['Ch10'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone service is redundant.\n",
    "print(\"Multiple Lines category counts:\\n\",ch.MultipleLines.value_counts())\n",
    "print(\"Phone Lines category counts:\\n\",ch.PhoneService.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ch.Ch10\n",
    "X = ch.drop(['customerID','Churn','Ch10','TotalCharges','PhoneService','Tenure Group','revloss'],axis=1,inplace=False).copy()\n",
    "temp = ch[['tenure','MonthlyCharges','SeniorCitizen']]\n",
    "X.drop(['tenure','MonthlyCharges','SeniorCitizen'],axis=1,inplace=True)\n",
    "X = X.apply(lambda x: x.astype('category')).apply(lambda x: x.cat.codes)\n",
    "X[['tenure','MonthlyCharges','SeniorCitizen']] = temp\n",
    "X1 = X.copy() # Saving a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will reduce all features to 2D by PCA.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  # Essential to see the effect of all\n",
    "X = sc.fit_transform(X)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "pca = PCA()\n",
    "xx = pca.fit_transform(X)\n",
    "xs = xx[:,0]\n",
    "ys = xx[:,1]\n",
    "fig.add_subplot(1,2,1)\n",
    "plt = plt.scatter(xs,ys,c=y)\n",
    "plt = plt.title('PCA analysis result by removing Total Charges')\n",
    "plt = plt.xlabel(\"PCA x component\")\n",
    "plt = plt.ylabel(\"PCA y component\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt = plt.bar(np.arange(pca.n_components_),100*np.round(pca.explained_variance_ratio_,4),color='m')\n",
    "plt = plt.xlabel(\"PCA Feature number\")\n",
    "plt = plt.ylabel(\"PCA Variance % \")\n",
    "plt = plt.title('Variance using PCA')\n",
    "print(\"Percentage Variance by removing TotalCharges:\",100*np.round(pca.explained_variance_ratio_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.drop(['MonthlyCharges'],axis=1,inplace=True)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "sc = StandardScaler()\n",
    "X1 = sc.fit_transform(X1)\n",
    "xx = pca.fit_transform(X1)\n",
    "xs = xx[:,0]\n",
    "ys = xx[:,1]\n",
    "fig.add_subplot(1,2,1)\n",
    "plt = plt.scatter(xs,ys,c=y)\n",
    "plt = plt.title('PCA analysis result by dropping monthly charges')\n",
    "plt = plt.xlabel(\"PCA x component\")\n",
    "plt = plt.ylabel(\"PCA y component\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt = plt.bar(np.arange(pca.n_components_),100*np.round(pca.explained_variance_ratio_,4),color='m')\n",
    "plt = plt.xlabel(\"PCA Feature number\")\n",
    "plt = plt.ylabel(\"PCA Variance %\")\n",
    "plt = plt.title('Variance using PCA')\n",
    "print(\"Percentage Variance by tenure and monthly charges:\",100*np.round(pca.explained_variance_ratio_,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans Model\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Graph and create 3 clusters of Customer Churn\n",
    "kmeans = KMeans(n_clusters=3,random_state=2)\n",
    "kmeans.fit(ch[ch.Churn=='Yes'][[\"tenure\",\"MonthlyCharges\"]])\n",
    "\n",
    "kmeans_colors = ['green' if c == 0 else 'blue' if c == 2 else 'red' for c in kmeans.labels_]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.subplot(2,1,1) #figsize=(10, 6))\n",
    "plt.scatter(x=\"tenure\",y=\"MonthlyCharges\", data=ch[ch.Churn=='Yes'],\n",
    "            alpha=0.25,color = kmeans_colors)\n",
    "plt.xlabel(\"Tenure in months \")\n",
    "plt.ylabel(\"Monthly Charges in Dollars\")\n",
    "plt.scatter(x=kmeans.cluster_centers_[:,0],y=kmeans.cluster_centers_[:,1],color=\"black\",marker=\"X\",s=100)\n",
    "plt.title(\"Clusters of Customers who switch\")\n",
    "print(\"Cluster Centers for loyal customers are at:\")\n",
    "print(\"Month, Dollars, Numbers\")\n",
    "print(np.round(kmeans.cluster_centers_[0,:],2),(kmeans.labels_==0).sum())\n",
    "print(np.round(kmeans.cluster_centers_[2,:],2),(kmeans.labels_==2).sum())\n",
    "print(np.round(kmeans.cluster_centers_[1,:],2),(kmeans.labels_==1).sum())\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "# Graph and create 3 clusters of Customer Churn\n",
    "kmeans = KMeans(n_clusters=3,random_state=2)\n",
    "kmeans.fit(ch[ch.Churn=='No'][[\"tenure\",\"MonthlyCharges\"]])\n",
    "\n",
    "kmeans_colors = ['darkgreen' if c == 0 else 'orange' if c == 2 else 'purple' for c in kmeans.labels_]\n",
    "\n",
    "plt.scatter(x=\"tenure\",y=\"MonthlyCharges\", data=ch[ch.Churn=='No'],\n",
    "            alpha=0.25,color = kmeans_colors)\n",
    "plt.xlabel(\"Tenure in months \")\n",
    "plt.ylabel(\"Monthly Charges in Dollars\")\n",
    "plt.scatter(x=kmeans.cluster_centers_[:,0],y=kmeans.cluster_centers_[:,1],color=\"black\",marker=\"X\",s=100)\n",
    "plt.title(\"Clusters of Loyal customers\")\n",
    "print(\"Cluster Centers for loyal customers are at:\")\n",
    "print(\"Month  Dollars  Numbers\")\n",
    "print(np.round(kmeans.cluster_centers_[1,:],2),(kmeans.labels_==1).sum())\n",
    "print(np.round(kmeans.cluster_centers_[0,:],2),(kmeans.labels_==0).sum())\n",
    "print(np.round(kmeans.cluster_centers_[2,:],2),(kmeans.labels_==2).sum())\n",
    "plt = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ch.drop(['customerID','Churn','Ch10','TotalCharges','PhoneService','Tenure Group','revloss'],axis=1,inplace=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=['gender','Partner','Dependents','PaperlessBilling','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaymentMethod']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(ch[var], prefix=var)\n",
    "    X1=X.join(cat_list)\n",
    "    X=X1\n",
    "X.drop(cat_vars,axis=1,inplace=True) # Originals need to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['MultipleLines_NoPh','InternetService_No','OnlineSecurity_No','OnlineBackup_No',\n",
    "        'DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No',        \n",
    "        'gender_Male','Partner_No','Dependents_No','PaperlessBilling_No',\n",
    "        'Contract_Month-to-month','PaymentMethod_Credit card (automatic)'],axis=1,inplace=True)\n",
    "X.drop(['StreamingMovies_NoInt','StreamingTV_NoInt','TechSupport_NoInt','DeviceProtection_NoInt','OnlineBackup_NoInt','OnlineSecurity_NoInt'],axis=1,inplace=True)\n",
    "XLin = X[[ 'MultipleLines_No', 'MultipleLines_Yes','InternetService_Fiber optic', 'InternetService_DSL',\n",
    "         'OnlineSecurity_Yes','OnlineBackup_Yes', 'DeviceProtection_Yes', 'TechSupport_Yes','StreamingTV_Yes', 'StreamingMovies_Yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Linear Regression for Monthly Charges using services\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LinReg = LinearRegression(fit_intercept=False)\n",
    "yLin = ch.MonthlyCharges\n",
    "LinReg.fit(XLin,yLin)\n",
    "pred = LinReg.predict(XLin)\n",
    "print(\"R^2 of the fit:\",np.round(LinReg.score(XLin,yLin),3))\n",
    "print(\"MSE of the model {:.2f}\".format(np.mean((pred - yLin) ** 2)))\n",
    "lincoeff = pd.DataFrame(np.round(LinReg.coef_,3),index=XLin.columns,columns=['$ Per month'])\n",
    "lincoeff.sort_values('$ Per month',ascending=False).plot.bar(color='orange')\n",
    "lincoeff.sort_values('$ Per month',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for verification of normality\n",
    "resid = pred-yLin\n",
    "sm = sm.qqplot(resid,line='r')\n",
    "plt = plt.title('Quantile Plot')\n",
    "plt = plt.figure()\n",
    "sns = sns.jointplot(pred,resid,color='r')\n",
    "plt = plt.title('Residual Plot')\n",
    "print(\"Percentage of outliers:{:.2f}\".format(100*((abs(resid) > 2.25).sum())*resid.std()/XLin.shape[0]))\n",
    "#(abs(resid) > resid.std()unt()\n",
    "#print(\"Indices of outlier points:\",list(np.argsort(abs(pred-ydev)).tail(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cust = round((np.sum(XLin,axis=0)*LinReg.coef_),2)\n",
    "index1 = y > 0\n",
    "churn_cust = round((np.sum(XLin.loc[index1,:],axis=0)*LinReg.coef_),2)\n",
    "joined = pd.concat([all_cust,churn_cust],axis=1)\n",
    "joined.columns = ['All Customers','Churn Customers']\n",
    "joined.plot.bar(width = 0.9)\n",
    "plt = plt.title('Monthly Income Bar Chart across services')\n",
    "plt = plt.ylabel('Monthly Income in Dollars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to drop a few dummies to prevent correlations, in nonservice specific ones.\n",
    "# Plotting correlation for top 10 features\n",
    "# Ref : https://matplotlib.org/examples/color/colormaps_reference.html for colormap\n",
    "X.drop('MonthlyCharges',axis=1,inplace=True)\n",
    "plt = plt.figure(figsize=(16,12))\n",
    "mask = np.zeros_like(X.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(X.corr(),mask=mask,cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf - original classifier\n",
    "# parameters - grid to search over\n",
    "# X - usually your training X matrix\n",
    "# y - usually your training y \n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=2, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    print(\"BEST\", gs.best_params_, gs.best_score_)\n",
    "    #print(gs.grid_scores_)\n",
    "    best = gs.best_estimator_\n",
    "    return best\n",
    "#------------------------------------------------------------------------------#\n",
    "# Function to plot ROC and find area under ROC                                 #\n",
    "#------------------------------------------------------------------------------#\n",
    "def find_auc_score(clf,Xin,yin,color='b',name='LogReg',label=1,prob=1) :\n",
    "    '''Function to plot Receiver characteristics and find AUC'''\n",
    "    if prob == 1:\n",
    "        yscore = clf.predict_proba(Xin)\n",
    "    else :\n",
    "        yscore = clf.decision_function(Xin)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(yin, yscore[:,label],pos_label=label)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate,color ,label='AUC '+name+' = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.01,1.01])\n",
    "    plt.ylim([-0.01,1.01])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def pre_process_Xy(Xarray,yarray,test_tr_split_size=0.4) :\n",
    "    '''Function to split given data into test and (train, dev) set'''\n",
    "    Xtr,Xdev,ytr,ydev = train_test_split(Xarray,yarray,test_size=test_tr_split_size,random_state=42,stratify=yarray)\n",
    "    return Xtr,Xdev,ytr,ydev\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #\n",
    "# Important parameters\n",
    "# indf - Input dataframe\n",
    "# featurenames - vector of names of predictors\n",
    "# targetname - name of column you want to predict (e.g. 0 or 1, 'M' or 'F', \n",
    "#              'yes' or 'no')\n",
    "# target1val - particular value you want to have as a 1 in the target\n",
    "# mask - boolean vector indicating test set (~mask is training set)\n",
    "# reuse_split - dictionary that contains traning and testing dataframes \n",
    "#              (we'll use this to test different classifiers on the same \n",
    "#              test-train splits)\n",
    "# score_func - we've used the accuracy as a way of scoring algorithms but \n",
    "#              this can be more general later on\n",
    "# n_folds - Number of folds for cross validation ()\n",
    "# n_jobs - used for parallelization\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #\n",
    "\n",
    "def plot_train_test_error(clf,X,y,N=50):\n",
    "    '''This function plots Train and Test Accuracy for different lengths'''\n",
    "\n",
    "    training_error = np.empty([N,1])\n",
    "    dev_error = np.empty([N,1])\n",
    "    len_tr = int(X.shape[0]/N)\n",
    "    re_ind = np.random.permutation(X.index)\n",
    "    X = X.reindex(re_ind)\n",
    "    y = y.reindex(re_ind)\n",
    "    for i in range(N) :\n",
    "        X1 = X[:(i+1)*len_tr]\n",
    "        y1 = y[:(i+1)*len_tr]\n",
    "        Xtr,Xte,ytr,yte = train_test_split(X1,y1,test_size=0.5,random_state=42,stratify=y1)\n",
    "        clf = clf.fit(Xtr, ytr)\n",
    "        training_error[i,0] = 1 - clf.score(Xtr, ytr)\n",
    "        dev_error[i,0] = 1 - clf.score(Xte, yte)\n",
    "    \n",
    "    plt.plot(np.arange(N)*len_tr,training_error.reshape(np.arange(N).shape),label='train error')\n",
    "    plt.plot(np.arange(N)*len_tr,dev_error.reshape(np.arange(N).shape),color='m',label='test error')\n",
    "    plt.title('Train Error and Test Error Vs Number of Samples used (train: test 1:1 ratio)')\n",
    "    plt.ylabel('Error rate')\n",
    "    plt.xlabel('Number of samples')\n",
    "    plt.legend(loc='best')\n",
    "    return\n",
    "    \n",
    "def do_classify(clf, parameters, Xtr,ytr,Xdev,ydev, score_func=None, n_folds=5, n_jobs=2,model_name='LogReg',label=1,prob_dec=1):\n",
    "\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtr, ytr, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtr, ytr)\n",
    "    training_accuracy = clf.score(Xtr, ytr)\n",
    "    test_accuracy = clf.score(Xdev, ydev)\n",
    "    print(\"############# based on standard predict ################\")\n",
    "    print(\"Accuracy on training data: %0.2f\" % (100*training_accuracy)+'%')\n",
    "    print(\"Accuracy on test data:     %0.2f\" % (100*test_accuracy)+'%')\n",
    "    print(\"confusion_matrix on dev data\")\n",
    "    ypred =  clf.predict(Xdev)\n",
    "    print(confusion_matrix(ydev,ypred))\n",
    "    print(\"classification report on dev data\")\n",
    "    print(classification_report(ydev,ypred))\n",
    "    print(\"########################################################\")\n",
    "  #  multi_auc_roc(clf,Xdev,ydev,prob=1)\n",
    "    auc_tr = find_auc_score(clf,Xtr,ytr,color='g',name=model_name+'_tr',label=label,prob=prob_dec) \n",
    "    auc_dev = find_auc_score(clf,Xdev,ydev,color='orange',name=model_name+'_dev',label=label,prob=prob_dec) \n",
    "    return clf,auc_tr,auc_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Keep a copy to access columns\n",
    "Xcpy = X.copy()\n",
    "X['tenure'] = X['tenure'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "Xtrain, Xdev, ytrain,ydev = train_test_split(X,y,test_size=0.4,stratify=y)\n",
    "# This is commented because hyperparameter tuning is not done currently.\n",
    "#Xdev, Xtest, ydev,ytest = train_test_split(Xt,yt,test_size=0.5,random_state=42,stratify=yt)\n",
    "parameters = {\"C\": [0.1,1,10,100,10000],\"class_weight\":['balanced',None]}\n",
    "logreg,aucrf1,aucrf2 = do_classify(LogisticRegression(), parameters, Xtrain,ytrain,Xdev,ydev, score_func='recall', n_folds=5, n_jobs=2,label=1,prob_dec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff=logreg.coef_\n",
    "intercept = logreg.intercept_\n",
    "coeffs_b= logreg.coef_[0,np.argsort(abs(logreg.coef_[0,:]))[::-1]]\n",
    "names_b = list(Xcpy.columns[np.argsort(abs(logreg.coef_[0,:]))[::-1]])\n",
    "logfimp = pd.DataFrame(np.round(coeffs_b,3),index=names_b,columns=['Coeff value'])\n",
    "df = logfimp.head(10).plot.bar(color='purple')\n",
    "plt = plt.title('Feature Importance (Log Reg)')\n",
    "plt = plt.ylabel('Coefficient value')\n",
    "plt = plt.xlabel('Features')\n",
    "logfimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying Feature Selection by limiting to 10\n",
    "from sklearn.feature_selection import RFE\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "rfe = RFE(model, 10)\n",
    "rfe = rfe.fit(Xtrain, ytrain)\n",
    "# After RFE has chosen, now do a prediction using that\n",
    "print(\"Chosen Predictors:\",Xcpy.columns[rfe.support_])\n",
    "Xp = Xcpy.loc[:,Xcpy.columns[rfe.support_]]\n",
    "Xp = sc.fit_transform(Xp)\n",
    "Xtrain1, Xt, ytrain1,yt = train_test_split(Xp,y,test_size=0.4,stratify=y)\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "logreg.fit(Xtrain1,ytrain1)\n",
    "yp = logreg.predict(Xt)\n",
    "print(\"Report:\\n\",classification_report(yt,yp))\n",
    "print(\"Dev Set Accuracy %\",np.round(accuracy_score(yt,yp)*100,2))\n",
    "print(\"Train set Accuracy %\",np.round(accuracy_score(ytrain1,logreg.predict(Xtrain1))*100,2))\n",
    "yprob = logreg.predict_proba(Xt)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(yt, yprob[:,1],pos_label=1)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt = plt.title('Receiver Operating Characteristic')\n",
    "plt = plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt = plt.legend(loc='lower right')\n",
    "plt = plt.plot([0,1],[0,1],'r--')\n",
    "plt = plt.xlim([-0.01,1.01])\n",
    "plt = plt.ylim([-0.01,1.01])\n",
    "plt = plt.ylabel('True Positive Rate')\n",
    "plt = plt.xlabel('False Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients with LogReg\n",
    "Xp = Xcpy.loc[:,Xcpy.columns[rfe.support_]]\n",
    "coeffs = logreg.coef_[0,np.argsort(abs(logreg.coef_[0,:]))[::-1]]\n",
    "names = list(Xp.columns[np.argsort(abs(logreg.coef_[0,:]))[::-1]])\n",
    "print(\"Coefficients and their values in decreasing importance\")\n",
    "pd.DataFrame(np.round(coeffs,2),index=names,columns=['Coeff value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate the extent of relation between churn and tenure, trying Logistic with tenure alone.\n",
    "# Recognizing that tenure and churn are just correlated, it may not be causation\n",
    "# We could verify if the coefficient with this is close to that obtained by the first \n",
    "# logistic regression that includes all variables\n",
    "logreg_red = LogisticRegression(class_weight='balanced')\n",
    "Xtrain, Xdev, ytrain,ydev = train_test_split(np.array(ch['tenure']),y,test_size=0.4,random_state=42,stratify=y)\n",
    "logreg_red.fit(Xtrain.reshape(-1,1),ytrain)\n",
    "ypred_red = logreg_red.predict_proba(Xdev.reshape(-1,1))\n",
    "plt = plt.plot(np.sort(ypred_red[:,1]),label = 'Probability values')\n",
    "ypred = logreg_red.predict(Xdev.reshape(-1,1))\n",
    "ypred_s = ypred[np.argsort(ypred_red[:,1])]\n",
    "spred = np.sort(ypred_red[:,1])\n",
    "vline = spred[ypred_s.argmax()]\n",
    "print(\"Threshold Chosen for classification:\",round(vline,2))\n",
    "print(\"Threshold Tenure:{} months\".format(round(0.997/0.037)))\n",
    "print(\"Max and Min Prob values:{} and {}\".format(round(ypred_red.max(),2),round(ypred_red.min(),2)))\n",
    "plt = plt.axhline(vline,color='k',linestyle='--',label = 'Threshold')\n",
    "plt = plt.scatter(np.arange(len(ypred)),ypred_s,color='m',marker='.',label = 'Predictions')\n",
    "plt = plt.legend(loc='best')\n",
    "plt = plt.xlabel('Test sample index')\n",
    "plt = plt.ylabel('Probability values')\n",
    "plt = plt.title('Probability Plot of Churn')\n",
    "print(\"Train Set Accuracy :{:.2f}%\".format(100*accuracy_score(ytrain,logreg_red.predict(Xtrain.reshape(-1,1)))))\n",
    "print(\"Dev Set Accuracy {:.2f}%\".format(100*accuracy_score(ydev,ypred)))\n",
    "print(\"Report:\\n\",classification_report(ydev,ypred))\n",
    "print(\"Coefficient:{}, Intercept:{}\".format(round(logreg_red.coef_[0,0],3),round(logreg_red.intercept_[0],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = X = ch.drop(['customerID','Churn','Ch10','TotalCharges','PhoneService','Tenure Group','revloss'],axis=1,inplace=False).copy()\n",
    "temp = X_rf[['tenure','MonthlyCharges','SeniorCitizen']]\n",
    "X_rf = X_rf.drop(['tenure','MonthlyCharges','SeniorCitizen'],axis=1)\n",
    "X_rf = X_rf.apply(lambda x: x.astype('category')).apply(lambda x: x.cat.codes)\n",
    "X_rf[['tenure','MonthlyCharges','SeniorCitizen']] = temp\n",
    "Xtrain, Xdev, ytrain,ydev = train_test_split(X_rf,y,test_size=0.4,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\"max_depth\": [3,4,6,8,12], 'min_samples_leaf': [1,2,4,8],\"class_weight\":['balanced',None]}\n",
    "tr,aucrf1,aucrf2 = do_classify(DecisionTreeClassifier(), parameters, Xtrain,ytrain,Xdev,ydev, score_func='recall', n_folds=5, n_jobs=2,model_name='DecTree',label=1,prob_dec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(tr, out_file='dtree.dot', \n",
    "                         feature_names=X_rf.columns,  \n",
    "                         class_names=['N','Y'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "#graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\"max_depth\": [3,4,6,8,12,None], 'min_samples_leaf': [1,2,4,6],\"n_estimators\":[10,50,100,200],\"class_weight\":['balanced',None]}\n",
    "rf,aucrf1,aucrf2 = do_classify(RandomForestClassifier(), parameters, Xtrain,ytrain,Xdev,ydev, score_func='recall', n_folds=5, n_jobs=2,model_name='RandomForest',label=1,prob_dec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = np.array(list(X_rf.columns))\n",
    "(pd.Series(rf.feature_importances_,index=feature_labels).sort_values(ascending=True)/np.max(rf.feature_importances_)).plot.barh(color='purple',width=0.9)\n",
    "plt = plt.title('Normalized Feature Importance From Random Forest Classifier')\n",
    "plt = plt.axvline(0.05,linestyle='--',color='olive')\n",
    "plt = plt.text(0.05,7,'5% of the max',rotation=87,fontsize=16)\n",
    "pd.DataFrame(rf.feature_importances_,index=feature_labels,columns=['Feature importance']).sort_values('Feature importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df[df['churn_prob'] >= 0.5]\n",
    "index1 = df_churn.sort_values('charge*prob',ascending=False).index\n",
    "temp = y*(df['churn_prob'] >= 0.5)\n",
    "index2 = ch.loc[(temp > 0),'MonthlyCharges'].index\n",
    "print(\"Potential revenue savings:${}\".format(round(ch.loc[index2,'MonthlyCharges'].head(1485).sum())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
